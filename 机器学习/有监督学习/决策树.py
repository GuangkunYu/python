"""
决策树：
    构建流程：
        1.准备工作：明确自变量和因变量，确定信息度量的方式（信息增益：熵、基尼系数），确定终止条件（纯度、记录条数、循环次数）
        2.选择特征：得到当前待处理子集，计算所有特征信息度量，得到当前最佳分类特征
        3.创建分支：根据选中特征将当前记录分成不同分支，分支个数取决于算法
        4.是否终止：判断是否满足终止条件，满足则退出循环，不满足则继续递归调用
        5.生成结果：判断是否需要剪枝，需要则进行适当的剪枝，不需要则为最终结果
    信息熵：
        描述混乱程度的度量
        取值范围0~1，值越大，越混乱
        公式：H(U) = - 求i个的和(pi * log pi)
    信息增益：
        信息是确定性的增加
        从一个状态到另一个状态信息的变化
        信息增益越大，对确定性贡献越大
    ID3系列算法（迭代树三代）：
        核心是信息熵，根据信息增益决定树的节点
        存在问题：
            信息度量不合理：倾向于选择取值多的字段
            输入类型单一：离散型
            不做剪枝，容易过拟合
    C4.5：和ID3相比的改进：
        用信息增益率代替信息增益
        能对连续属性进行离散化，对不完整数据进行处理
        进行剪枝
    C50：C4.5相比的改进：
        使用了boosting
        前修剪、后修剪
    CART（分类回归树）:
        核心是基尼系数
        分类是二叉树
        支持连续值和离散值
        后剪枝进行修剪
        支持回归，可以预测连续值

    算法  支持模型     树结构     特征选择    连续值处理    缺失值处理     剪枝
    ID3     分类      多叉树     信息增益      不支持      不支持       不支持
    C4.5    分类      多叉树     信息增益比     支持        支持         支持
    CART 分类，回归    二叉树     基尼系数      支持         支持         支持
"""