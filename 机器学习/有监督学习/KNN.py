"""
KNN:
    核心思想是如果离某一个样本最近的K个样本中的大多数属于某一个类别，
    则该样本也属于这个类别，并具有这个类别上样本的特性。
    KNN不但可以预测分类，还可以做回归分析（预测具体的值）

    有N个已知分类结果的样本点，对新纪录r使用KNN将其分类的步骤：
        1.确定K值，确定计算距离的公式，比如欧式距离
        2.计算r和其他样本点之间的距离d
        3.得到目前和r最接近的K个样本，作为KNN距的训练样本
        4.将K个样本中最多归属类别的分类标签赋予新纪录r，分类结束

    优点：
        1.原理简单，容易理解，容易实现
        2.重新训练代价较低
        3.时间、空间复杂度取决于训练集（一般不算太大）
    缺点：
        1.KNN属于惰性学习算法，得到结果的及时性差
        2.K值对结果影响大
        3.不同类记录相差较大时容易误判
        4.样本点较多时，计算量较大
        5.相对于决策树，结果可解释性不强
"""